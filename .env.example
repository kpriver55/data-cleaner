# LLM Provider Configuration
# Choose your LLM provider: ollama, openai, anthropic, together, anyscale
LLM_PROVIDER=ollama

# Model name for your chosen provider
# Examples:
#   Ollama: qwen2.5:7b-instruct-q5_k_m, llama3.1:8b-instruct-q5_k_M
#   OpenAI: gpt-4o, gpt-4o-mini, gpt-4-turbo
#   Anthropic: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
#   Together AI: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
#   Anyscale: meta-llama/Meta-Llama-3.1-8B-Instruct
LLM_MODEL=qwen2.5:7b-instruct-q5_k_m

# Ollama Configuration (for local deployments)
OLLAMA_API_BASE=http://localhost:11434

# OpenAI API Key (required when LLM_PROVIDER=openai)
# Get your key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-...

# Anthropic API Key (required when LLM_PROVIDER=anthropic)
# Get your key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-...

# Together AI API Key (required when LLM_PROVIDER=together)
# Get your key from: https://api.together.xyz/settings/api-keys
# TOGETHER_API_KEY=...

# Anyscale API Key (required when LLM_PROVIDER=anyscale)
# Get your key from: https://console.anyscale.com/
# ANYSCALE_API_KEY=...
